{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Warmup\n",
    "\n",
    "\"I before E except after C\" is perhaps the most famous English spelling rule. For the purpose of this challenge, the rule says:\n",
    "\n",
    "if \"ei\" appears in a word, it must immediately follow \"c\".\n",
    "If \"ie\" appears in a word, it must not immediately follow \"c\"\n",
    ".\n",
    "A word also follows the rule if neither \"ei\" nor \"ie\" appears anywhere in the word. Examples of words that follow this rule are:\n",
    "\n",
    "fiery hierarchy hieroglyphic\n",
    "ceiling inconceivable receipt\n",
    "daily programmer one two three\n",
    "\n",
    "There are many exceptions that don't follow this rule, such as:\n",
    "\n",
    "sleigh stein fahrenheit\n",
    "deifies either nuclei reimburse\n",
    "ancient juicier societies\n",
    "\n",
    "Write a function that tells you whether or not a given word follows the \"I before E\" rule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def follows_rule(word):\n",
    "    raise NotImplementedError\n",
    "\n",
    "for word in [\n",
    "        \"fiery\",\n",
    "        \"hierarchy\",\n",
    "        \"hieroglyphic\",\n",
    "        \"ceiling\",\n",
    "        \"inconceivable\",\n",
    "        \"receipt\",\n",
    "        \"daily\",\n",
    "        \"programmer\",\n",
    "        \"one\",\n",
    "        \"two\",\n",
    "        \"three\"\n",
    "]:\n",
    "    assert follows_rule(word)\n",
    "    \n",
    "for word in [\n",
    "    \"sleigh\",\n",
    "    \"stein\",\n",
    "    \"fahrenheit\",\n",
    "    \"deifies\",\n",
    "    \"either\",\n",
    "    \"nuclei\",\n",
    "    \"reimburse\",\n",
    "    \"ancient\",\n",
    "    \"juicier\",\n",
    "    \"societies\"\n",
    "]:\n",
    "    assert not follows_rule(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code demonstrates training a model locally to predict a person's identity based off a pixel-encoded image.\n",
    "\n",
    "1. Add code to do the following:\n",
    "    - Upsert an experiment in mlflow\n",
    "    - Create a new run in mlflow\n",
    "    - Log the params, metric, tag the model and log the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load the Olivetti dataset\n",
    "X, y = datasets.fetch_olivetti_faces(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Hyperparameters\n",
    "params = {\n",
    "    \"solver\": \"lbfgs\",\n",
    "    \"max_iter\": 1000,\n",
    "    \"multi_class\": \"auto\",\n",
    "    \"random_state\": 8888,\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Navigate to the MLflow UI to see the results of the experiment\n",
    "    - Discuss what they mean\n",
    "    - Discuss what the different data available in the UI means\n",
    "    - Discuss what other metrics we may want to track and what other changes could be made to the code to track them (can also check documentation for ideas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now update the previous code to run a grid search across at least one alternative model and various hyper-parameters\n",
    "    - Create a new experiment for the grid search\n",
    "    - Create an individual run for each model type\n",
    "        - Optional (bonus): create an individual run for each hyper-parameter combination\n",
    "    - Log metrics params etc for the best iteration of each model as an individual run under the experiment\n",
    "    - Log the best model in terms of accuracy as a separate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for problem 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Now load the best model locally and evaluate it (you can use the test data from the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Now let's deploy our model using hosted inference\n",
    "    - We provide credentials for AWS to deploy with sagemaker, but you can also deploy to any other platform that you are familiar with\n",
    "Guide for testing and deploying to sagemaker here: https://mlflow.org/docs/latest/deployment/deploy-model-to-sagemaker.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for problem 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
